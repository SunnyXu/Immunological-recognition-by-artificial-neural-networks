1, 0.321353735, 68.03%, 68.75%
2, 0.239116319, 75.21%, 75.54%
3, 0.205610776, 79.06%, 79.30%
4, 0.184670097, 81.61%, 82.27%
5, 0.169760323, 83.45%, 84.13%
6, 0.158393695, 84.73%, 85.49%
7, 0.149336007, 85.85%, 86.87%
8, 0.141885300, 86.97%, 88.00%
9, 0.135607437, 87.91%, 88.88%
10, 0.130217444, 88.91%, 89.73%
11, 0.125519402, 89.88%, 90.39%
12, 0.121373564, 90.33%, 90.96%
13, 0.117677069, 90.82%, 91.40%
14, 0.114352290, 91.52%, 91.76%
15, 0.111339311, 92.15%, 92.01%
16, 0.108591018, 92.42%, 92.40%
17, 0.106069796, 92.85%, 92.78%
18, 0.103745179, 93.30%, 93.03%
19, 0.101592155, 93.58%, 93.28%
20, 0.099590012, 93.73%, 93.46%
21, 0.097721407, 94.00%, 93.58%
22, 0.095971645, 94.09%, 93.78%
23, 0.094328239, 94.21%, 93.94%
24, 0.092780540, 94.45%, 94.09%
25, 0.091319286, 94.55%, 94.13%
26, 0.089936410, 94.61%, 94.24%
27, 0.088624955, 94.70%, 94.42%
28, 0.087378770, 94.88%, 94.60%
29, 0.086192396, 94.97%, 94.73%
30, 0.085061017, 95.18%, 94.82%
31, 0.083980397, 95.42%, 94.94%
32, 0.082946702, 95.48%, 95.04%
33, 0.081956494, 95.55%, 95.09%
34, 0.081006654, 95.64%, 95.15%
35, 0.080094454, 95.70%, 95.27%
36, 0.079217379, 95.73%, 95.33%
37, 0.078373141, 95.82%, 95.40%
38, 0.077559679, 95.88%, 95.52%
39, 0.076775071, 95.91%, 95.55%
40, 0.076017610, 96.00%, 95.64%
41, 0.075285657, 96.03%, 95.76%
42, 0.074577786, 96.03%, 95.81%
43, 0.073892663, 96.03%, 95.85%
44, 0.073229022, 96.03%, 95.88%
45, 0.072585735, 96.15%, 95.93%
46, 0.071961741, 96.21%, 95.94%
47, 0.071356048, 96.30%, 96.00%
48, 0.070767767, 96.36%, 96.07%
49, 0.070196025, 96.48%, 96.18%
50, 0.069640042, 96.55%, 96.21%
51, 0.069099067, 96.64%, 96.28%
52, 0.068572415, 96.67%, 96.33%
53, 0.068059449, 96.70%, 96.37%
54, 0.067559564, 96.76%, 96.37%
55, 0.067072192, 96.82%, 96.43%
56, 0.066596787, 96.85%, 96.45%
57, 0.066132843, 96.85%, 96.48%
58, 0.065679897, 96.82%, 96.58%
59, 0.065237522, 96.82%, 96.58%
60, 0.064805270, 96.82%, 96.64%
61, 0.064382762, 96.82%, 96.72%
62, 0.063969613, 96.82%, 96.73%
63, 0.063565497, 96.85%, 96.73%
64, 0.063170054, 96.88%, 96.76%
65, 0.062782944, 96.88%, 96.78%
66, 0.062403906, 96.91%, 96.79%
67, 0.062032644, 96.91%, 96.81%
68, 0.061668878, 96.91%, 96.81%
69, 0.061312357, 96.91%, 96.82%
70, 0.060962843, 96.94%, 96.82%
71, 0.060620061, 96.97%, 96.84%
72, 0.060283816, 96.97%, 96.84%
73, 0.059953911, 96.97%, 96.84%
74, 0.059630122, 97.00%, 96.87%
75, 0.059312240, 97.03%, 96.90%
76, 0.059000091, 97.09%, 96.91%
77, 0.058693523, 97.09%, 96.96%
78, 0.058392350, 97.12%, 96.99%
79, 0.058096393, 97.12%, 97.01%
80, 0.057805528, 97.18%, 97.03%
81, 0.057519583, 97.18%, 97.03%
82, 0.057238418, 97.21%, 97.06%
83, 0.056961897, 97.21%, 97.10%
84, 0.056689873, 97.21%, 97.12%
85, 0.056422247, 97.24%, 97.16%
86, 0.056158893, 97.27%, 97.18%
87, 0.055899689, 97.27%, 97.18%
88, 0.055644512, 97.27%, 97.19%
89, 0.055393255, 97.30%, 97.21%
90, 0.055145832, 97.30%, 97.22%
91, 0.054902154, 97.30%, 97.28%
92, 0.054662096, 97.30%, 97.30%
93, 0.054425579, 97.30%, 97.31%
94, 0.054192499, 97.30%, 97.33%
95, 0.053962798, 97.30%, 97.33%
96, 0.053736364, 97.30%, 97.34%
97, 0.053513090, 97.30%, 97.37%
98, 0.053292948, 97.33%, 97.40%
99, 0.053075861, 97.33%, 97.45%
100, 0.052861744, 97.36%, 97.48%
test accuracy = 97.36%, train accuracy = 97.48%
