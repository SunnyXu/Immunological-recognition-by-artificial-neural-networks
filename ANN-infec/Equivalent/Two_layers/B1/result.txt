1, 0.661021452, 49.15%, 50.42%
2, 0.656656366, 49.15%, 50.42%
3, 0.652622935, 49.15%, 50.42%
4, 0.648561387, 49.15%, 50.42%
5, 0.644425204, 49.15%, 50.42%
6, 0.640176292, 49.15%, 50.42%
7, 0.635784845, 49.27%, 50.49%
8, 0.631229351, 49.91%, 51.24%
9, 0.626496795, 52.21%, 53.06%
10, 0.621582902, 55.67%, 56.43%
11, 0.616492244, 60.67%, 61.06%
12, 0.611238125, 65.33%, 65.42%
13, 0.605842220, 68.67%, 68.84%
14, 0.600333771, 71.06%, 71.10%
15, 0.594748404, 73.42%, 73.36%
16, 0.589126542, 75.15%, 74.90%
17, 0.583511541, 76.39%, 75.85%
18, 0.577947674, 77.09%, 76.42%
19, 0.572478076, 77.82%, 76.97%
20, 0.567142874, 78.18%, 77.75%
21, 0.561977664, 78.48%, 77.99%
22, 0.557012296, 78.73%, 78.24%
23, 0.552270275, 79.06%, 78.49%
24, 0.547768472, 79.42%, 78.69%
25, 0.543517337, 79.85%, 79.06%
26, 0.539521425, 80.36%, 79.30%
27, 0.535780157, 80.58%, 79.57%
28, 0.532288526, 80.82%, 79.90%
29, 0.529038240, 80.97%, 80.03%
30, 0.526018466, 81.18%, 80.22%
31, 0.523216605, 81.21%, 80.37%
32, 0.520619010, 81.30%, 80.52%
33, 0.518211595, 81.27%, 80.69%
34, 0.515980227, 81.39%, 80.81%
35, 0.513911119, 81.45%, 80.82%
36, 0.511991066, 81.45%, 80.87%
37, 0.510207602, 81.67%, 80.99%
38, 0.508549076, 81.79%, 81.04%
39, 0.507004746, 81.79%, 81.06%
40, 0.505564762, 81.88%, 81.13%
41, 0.504220148, 81.79%, 81.21%
42, 0.502962771, 81.73%, 81.16%
43, 0.501785276, 81.85%, 81.15%
44, 0.500681042, 81.85%, 81.21%
45, 0.499644097, 81.85%, 81.12%
46, 0.498669087, 81.94%, 81.18%
47, 0.497751203, 81.91%, 81.24%
48, 0.496886069, 81.94%, 81.24%
49, 0.496069814, 82.06%, 81.19%
50, 0.495298921, 82.09%, 81.12%
51, 0.494570205, 81.88%, 81.07%
52, 0.493880789, 81.79%, 81.07%
53, 0.493228061, 81.70%, 81.03%
54, 0.492609650, 81.64%, 81.00%
55, 0.492023397, 81.61%, 80.96%
56, 0.491467312, 81.58%, 80.91%
57, 0.490939579, 81.58%, 80.88%
58, 0.490438511, 81.64%, 80.90%
59, 0.489962579, 81.61%, 80.90%
60, 0.489510347, 81.61%, 80.84%
61, 0.489080493, 81.61%, 80.87%
62, 0.488671790, 81.58%, 80.87%
63, 0.488283071, 81.55%, 80.84%
64, 0.487913275, 81.55%, 80.79%
65, 0.487561374, 81.42%, 80.73%
66, 0.487226458, 81.33%, 80.67%
67, 0.486907620, 81.33%, 80.70%
68, 0.486604046, 81.27%, 80.64%
69, 0.486314945, 81.27%, 80.64%
70, 0.486039580, 81.24%, 80.64%
71, 0.485777243, 81.18%, 80.58%
72, 0.485527303, 81.15%, 80.55%
73, 0.485289119, 81.12%, 80.54%
74, 0.485062111, 81.09%, 80.49%
75, 0.484845722, 81.12%, 80.52%
76, 0.484639447, 81.12%, 80.52%
77, 0.484442763, 81.06%, 80.52%
78, 0.484255209, 81.09%, 80.48%
79, 0.484076354, 81.00%, 80.49%
80, 0.483905752, 81.00%, 80.46%
81, 0.483743012, 81.00%, 80.45%
82, 0.483587754, 80.94%, 80.48%
83, 0.483439625, 80.97%, 80.48%
84, 0.483298267, 80.97%, 80.49%
85, 0.483163371, 80.97%, 80.51%
86, 0.483034621, 80.94%, 80.54%
87, 0.482911731, 80.91%, 80.52%
88, 0.482794413, 80.91%, 80.51%
89, 0.482682414, 80.91%, 80.49%
90, 0.482575481, 80.88%, 80.51%
91, 0.482473384, 80.85%, 80.54%
92, 0.482375891, 80.82%, 80.51%
93, 0.482282784, 80.79%, 80.51%
94, 0.482193864, 80.79%, 80.52%
95, 0.482108931, 80.79%, 80.49%
96, 0.482027810, 80.79%, 80.48%
97, 0.481950322, 80.82%, 80.43%
98, 0.481876300, 80.85%, 80.43%
99, 0.481805591, 80.85%, 80.43%
100, 0.481738035, 80.85%, 80.42%
test accuracy = 80.85%, train accuracy = 80.42%
