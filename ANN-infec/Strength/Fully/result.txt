1, 0.148630350, 85.45%, 85.09%
2, 0.073787274, 87.70%, 87.09%
3, 0.062727166, 89.36%, 88.76%
4, 0.058715290, 90.30%, 89.66%
5, 0.057011875, 90.97%, 90.28%
6, 0.056274484, 91.30%, 90.76%
7, 0.055952697, 91.45%, 91.10%
8, 0.055777134, 91.52%, 91.39%
9, 0.055606592, 91.79%, 91.58%
10, 0.055368750, 92.03%, 91.82%
11, 0.055030672, 92.27%, 92.09%
12, 0.054580372, 92.36%, 92.28%
13, 0.054015597, 92.42%, 92.57%
14, 0.053338585, 92.58%, 92.61%
15, 0.052553979, 92.79%, 92.84%
16, 0.051668044, 92.91%, 92.97%
17, 0.050688344, 93.03%, 93.18%
18, 0.049623481, 93.24%, 93.42%
19, 0.048482942, 93.36%, 93.64%
20, 0.047277009, 93.52%, 93.84%
21, 0.046016647, 93.73%, 94.04%
22, 0.044713324, 94.03%, 94.31%
23, 0.043378724, 94.33%, 94.51%
24, 0.042024470, 94.58%, 94.78%
25, 0.040661762, 94.64%, 95.06%
26, 0.039301321, 94.82%, 95.19%
27, 0.037953176, 95.00%, 95.45%
28, 0.036626460, 95.18%, 95.64%
29, 0.035329061, 95.42%, 95.85%
30, 0.034067381, 95.48%, 96.00%
31, 0.032846258, 95.52%, 96.12%
32, 0.031669023, 95.48%, 96.30%
33, 0.030537677, 95.55%, 96.39%
34, 0.029453142, 95.61%, 96.55%
35, 0.028415511, 95.64%, 96.79%
36, 0.027424212, 95.73%, 96.93%
37, 0.026478233, 95.82%, 97.04%
38, 0.025576230, 95.76%, 97.07%
39, 0.024716684, 95.79%, 97.06%
40, 0.023897964, 95.70%, 97.13%
41, 0.023118413, 95.61%, 97.10%
42, 0.022376390, 95.61%, 97.10%
43, 0.021670303, 95.58%, 97.06%
44, 0.020998582, 95.55%, 97.06%
45, 0.020359682, 95.42%, 97.04%
46, 0.019752116, 95.42%, 97.03%
47, 0.019174398, 95.42%, 97.00%
48, 0.018625087, 95.30%, 96.99%
49, 0.018102752, 95.30%, 96.97%
50, 0.017605996, 95.18%, 96.94%
51, 0.017133464, 95.12%, 96.94%
52, 0.016683873, 95.09%, 96.91%
53, 0.016255953, 95.09%, 96.84%
54, 0.015848520, 95.03%, 96.81%
55, 0.015460446, 95.06%, 96.82%
56, 0.015090667, 95.06%, 96.82%
57, 0.014738167, 95.15%, 96.81%
58, 0.014401998, 95.18%, 96.81%
59, 0.014081277, 95.18%, 96.78%
60, 0.013775152, 95.18%, 96.73%
61, 0.013482824, 95.15%, 96.76%
62, 0.013203553, 95.18%, 96.81%
63, 0.012936609, 95.18%, 96.87%
64, 0.012681325, 95.18%, 96.93%
65, 0.012437065, 95.21%, 96.94%
66, 0.012203212, 95.24%, 96.96%
67, 0.011979203, 95.24%, 97.03%
68, 0.011764501, 95.24%, 97.04%
69, 0.011558622, 95.24%, 97.09%
70, 0.011361075, 95.24%, 97.16%
71, 0.011171441, 95.21%, 97.22%
72, 0.010989306, 95.27%, 97.24%
73, 0.010814283, 95.27%, 97.27%
74, 0.010646020, 95.30%, 97.31%
75, 0.010484181, 95.33%, 97.33%
76, 0.010328460, 95.30%, 97.33%
77, 0.010178576, 95.33%, 97.34%
78, 0.010034249, 95.36%, 97.37%
79, 0.009895232, 95.36%, 97.42%
80, 0.009761293, 95.39%, 97.45%
81, 0.009632203, 95.42%, 97.46%
82, 0.009507753, 95.42%, 97.51%
83, 0.009387740, 95.45%, 97.54%
84, 0.009271977, 95.42%, 97.57%
85, 0.009160283, 95.48%, 97.61%
86, 0.009052484, 95.52%, 97.63%
87, 0.008948431, 95.52%, 97.64%
88, 0.008847949, 95.55%, 97.70%
89, 0.008750892, 95.52%, 97.73%
90, 0.008657105, 95.55%, 97.75%
91, 0.008566440, 95.61%, 97.76%
92, 0.008478755, 95.64%, 97.79%
93, 0.008393914, 95.70%, 97.87%
94, 0.008311797, 95.76%, 97.88%
95, 0.008232274, 95.76%, 97.91%
96, 0.008155231, 95.79%, 97.94%
97, 0.008080580, 95.79%, 97.96%
98, 0.008008212, 95.79%, 98.00%
99, 0.007938049, 95.79%, 98.03%
100, 0.007870012, 95.82%, 98.03%
test accuracy = 95.82%, train accuracy = 98.03%
