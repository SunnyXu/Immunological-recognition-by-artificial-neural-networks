1, 0.660310030, 55.82%, 57.03%
2, 0.630702038, 63.12%, 63.73%
3, 0.610908235, 65.67%, 66.19%
4, 0.596595713, 67.09%, 67.81%
5, 0.585582727, 68.15%, 68.97%
6, 0.576699986, 68.79%, 69.75%
7, 0.569280996, 69.18%, 70.34%
8, 0.562922829, 69.36%, 70.76%
9, 0.557368157, 69.85%, 71.00%
10, 0.552444511, 70.27%, 71.30%
11, 0.548031350, 70.64%, 71.46%
12, 0.544041081, 70.97%, 71.57%
13, 0.540407977, 71.36%, 71.70%
14, 0.537081268, 71.48%, 71.93%
15, 0.534020765, 71.48%, 72.19%
16, 0.531194080, 71.58%, 72.43%
17, 0.528574635, 71.82%, 72.52%
18, 0.526140092, 72.24%, 72.69%
19, 0.523871696, 72.42%, 72.93%
20, 0.521753333, 72.70%, 73.12%
21, 0.519771075, 73.00%, 73.31%
22, 0.517912786, 73.03%, 73.49%
23, 0.516167895, 73.21%, 73.66%
24, 0.514526993, 73.21%, 73.78%
25, 0.512981796, 73.42%, 73.88%
26, 0.511524807, 73.45%, 74.01%
27, 0.510149388, 73.73%, 74.06%
28, 0.508849561, 73.82%, 74.07%
29, 0.507619727, 73.76%, 74.15%
30, 0.506455086, 73.73%, 74.24%
31, 0.505351167, 73.76%, 74.27%
32, 0.504303837, 73.97%, 74.22%
33, 0.503309370, 73.94%, 74.28%
34, 0.502364449, 74.09%, 74.31%
35, 0.501465839, 74.21%, 74.39%
36, 0.500610738, 74.24%, 74.49%
37, 0.499796441, 74.18%, 74.49%
38, 0.499020449, 74.33%, 74.54%
39, 0.498280583, 74.36%, 74.63%
40, 0.497574700, 74.39%, 74.67%
41, 0.496900866, 74.45%, 74.67%
42, 0.496257270, 74.58%, 74.69%
43, 0.495642253, 74.58%, 74.67%
44, 0.495054206, 74.64%, 74.75%
45, 0.494491739, 74.73%, 74.79%
46, 0.493953344, 74.70%, 74.75%
47, 0.493437849, 74.82%, 74.70%
48, 0.492944141, 74.85%, 74.69%
49, 0.492471066, 74.91%, 74.67%
50, 0.492017500, 74.94%, 74.67%
51, 0.491582529, 74.82%, 74.69%
52, 0.491165287, 74.88%, 74.70%
53, 0.490764829, 74.91%, 74.70%
54, 0.490380323, 74.85%, 74.72%
55, 0.490011076, 74.82%, 74.69%
56, 0.489656289, 74.82%, 74.73%
57, 0.489315384, 74.88%, 74.78%
58, 0.488987694, 74.88%, 74.82%
59, 0.488672586, 74.85%, 74.82%
60, 0.488369501, 74.85%, 74.85%
61, 0.488077926, 74.85%, 74.87%
62, 0.487797263, 74.85%, 74.88%
63, 0.487527190, 74.91%, 74.90%
64, 0.487267152, 74.91%, 74.91%
65, 0.487016666, 74.97%, 74.96%
66, 0.486775433, 74.97%, 75.00%
67, 0.486542980, 74.97%, 75.00%
68, 0.486318918, 75.03%, 74.97%
69, 0.486102998, 75.00%, 74.96%
70, 0.485894797, 75.09%, 74.96%
71, 0.485693976, 75.12%, 75.01%
72, 0.485500319, 75.15%, 75.07%
73, 0.485313473, 75.12%, 75.06%
74, 0.485133252, 75.12%, 75.03%
75, 0.484959273, 75.12%, 75.04%
76, 0.484791451, 75.12%, 75.07%
77, 0.484629375, 75.12%, 75.12%
78, 0.484472847, 75.15%, 75.13%
79, 0.484321730, 75.21%, 75.12%
80, 0.484175751, 75.27%, 75.10%
81, 0.484034814, 75.30%, 75.09%
82, 0.483898561, 75.30%, 75.13%
83, 0.483766925, 75.33%, 75.15%
84, 0.483639762, 75.33%, 75.16%
85, 0.483516832, 75.36%, 75.16%
86, 0.483398057, 75.39%, 75.13%
87, 0.483283203, 75.36%, 75.12%
88, 0.483172152, 75.36%, 75.13%
89, 0.483064714, 75.39%, 75.19%
90, 0.482960877, 75.39%, 75.16%
91, 0.482860454, 75.39%, 75.21%
92, 0.482763278, 75.39%, 75.19%
93, 0.482669259, 75.42%, 75.19%
94, 0.482578310, 75.42%, 75.19%
95, 0.482490315, 75.45%, 75.19%
96, 0.482405137, 75.45%, 75.19%
97, 0.482322706, 75.42%, 75.16%
98, 0.482242948, 75.39%, 75.18%
99, 0.482165691, 75.45%, 75.22%
100, 0.482090950, 75.48%, 75.24%
test accuracy = 75.48%, train accuracy = 75.24%
