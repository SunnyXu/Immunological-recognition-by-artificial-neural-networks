1, 0.663276145, 49.15%, 50.42%
2, 0.660487074, 49.15%, 50.42%
3, 0.658019957, 49.15%, 50.42%
4, 0.655576254, 49.15%, 50.42%
5, 0.653132744, 49.15%, 50.42%
6, 0.650670091, 49.15%, 50.42%
7, 0.648172554, 49.15%, 50.42%
8, 0.645627824, 49.18%, 50.43%
9, 0.643026860, 50.24%, 51.31%
10, 0.640363847, 54.67%, 56.70%
11, 0.637636165, 58.03%, 60.49%
12, 0.634844321, 59.67%, 61.63%
13, 0.631991801, 59.91%, 61.85%
14, 0.629084962, 59.97%, 61.78%
15, 0.626132796, 60.21%, 62.04%
16, 0.623146591, 60.36%, 62.16%
17, 0.620139490, 60.42%, 62.13%
18, 0.617126082, 60.03%, 61.97%
19, 0.614121811, 60.12%, 62.01%
20, 0.611142458, 60.42%, 61.93%
21, 0.608203529, 60.36%, 61.85%
22, 0.605319769, 60.36%, 62.13%
23, 0.602504707, 60.58%, 62.36%
24, 0.599770250, 60.61%, 62.42%
25, 0.597126465, 60.67%, 62.54%
26, 0.594581364, 60.97%, 62.85%
27, 0.592140942, 61.24%, 63.03%
28, 0.589809175, 61.36%, 63.10%
29, 0.587588181, 61.42%, 63.28%
30, 0.585478388, 61.48%, 63.34%
31, 0.583478771, 61.58%, 63.60%
32, 0.581587093, 61.70%, 63.75%
33, 0.579800189, 61.97%, 63.97%
34, 0.578114180, 62.30%, 64.12%
35, 0.576524669, 62.52%, 64.12%
36, 0.575026947, 62.61%, 64.18%
37, 0.573616185, 62.58%, 64.22%
38, 0.572287466, 62.64%, 64.27%
39, 0.571035970, 62.58%, 64.31%
40, 0.569857014, 62.52%, 64.30%
41, 0.568746104, 62.58%, 64.37%
42, 0.567698975, 62.70%, 64.46%
43, 0.566711582, 62.64%, 64.57%
44, 0.565780137, 62.67%, 64.66%
45, 0.564901090, 62.70%, 64.73%
46, 0.564071140, 62.79%, 64.76%
47, 0.563287202, 62.91%, 64.87%
48, 0.562546430, 63.06%, 65.01%
49, 0.561846163, 63.15%, 65.19%
50, 0.561183920, 63.42%, 65.39%
51, 0.560557404, 63.79%, 65.45%
52, 0.559964473, 63.67%, 65.61%
53, 0.559403133, 63.85%, 65.79%
54, 0.558871495, 64.06%, 65.91%
55, 0.558367830, 64.15%, 66.04%
56, 0.557890512, 64.27%, 66.06%
57, 0.557438007, 64.42%, 66.12%
58, 0.557008882, 64.61%, 66.25%
59, 0.556601803, 64.91%, 66.25%
60, 0.556215510, 64.97%, 66.33%
61, 0.555848811, 65.00%, 66.42%
62, 0.555500595, 65.15%, 66.49%
63, 0.555169824, 65.30%, 66.55%
64, 0.554855512, 65.52%, 66.61%
65, 0.554556748, 65.64%, 66.67%
66, 0.554272652, 65.64%, 66.72%
67, 0.554002398, 65.70%, 66.78%
68, 0.553745236, 65.76%, 66.76%
69, 0.553500434, 65.82%, 66.79%
70, 0.553267320, 65.76%, 66.85%
71, 0.553045252, 65.88%, 66.91%
72, 0.552833637, 65.94%, 66.96%
73, 0.552631905, 66.09%, 66.97%
74, 0.552439525, 66.12%, 66.94%
75, 0.552255995, 66.09%, 66.91%
76, 0.552080856, 66.09%, 66.93%
77, 0.551913647, 66.09%, 66.96%
78, 0.551753969, 66.06%, 66.94%
79, 0.551601432, 66.06%, 66.99%
80, 0.551455666, 66.12%, 66.99%
81, 0.551316317, 66.15%, 67.00%
82, 0.551183081, 66.24%, 67.03%
83, 0.551055632, 66.30%, 67.03%
84, 0.550933703, 66.27%, 67.06%
85, 0.550816994, 66.33%, 67.09%
86, 0.550705265, 66.24%, 67.09%
87, 0.550598284, 66.24%, 67.07%
88, 0.550495809, 66.18%, 67.06%
89, 0.550397640, 66.21%, 67.07%
90, 0.550303567, 66.21%, 67.07%
91, 0.550213399, 66.15%, 67.10%
92, 0.550126958, 66.12%, 67.13%
93, 0.550044081, 66.12%, 67.10%
94, 0.549964602, 66.12%, 67.13%
95, 0.549888364, 66.15%, 67.18%
96, 0.549815232, 66.18%, 67.16%
97, 0.549745067, 66.18%, 67.18%
98, 0.549677745, 66.21%, 67.18%
99, 0.549613134, 66.21%, 67.19%
100, 0.549551127, 66.15%, 67.21%
test accuracy = 66.15%, train accuracy = 67.21%
